{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GPF-UNLgrn2V"
   },
   "outputs": [],
   "source": [
    "#Task: ABSA\n",
    "#Language: Arabic\n",
    "#Contact: Lily Foula <lilyfoula@gmail.com>\n",
    "#Last Update: 2025-06-26\n",
    "#Requirements: flair, transformers, ipymarkup\n",
    "#Encoding: UTF-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKp8tagern2X"
   },
   "source": [
    "# Aspect-Based Sentiment Analysis (ABSA) with FLAIR\n",
    "\n",
    "This Notebook shows you how to perform ABSA, which consists of two sub-tasks.\n",
    "- Task A: Extraction of **Aspects** from unlabelled text\n",
    "- Task B: Finding the sentiment associated with each **Aspect**.\n",
    "\n",
    "**Aspects** can be any entities of interest in the text for which we want to find out the associated sentiment. This mostly depends on the kind of data you are working on. For example, the **Aspects** in a news corpora might be person names and organizations, while **Aspects** in a dataset of restaurant reviews might be names of dishes and drinks.\n",
    "\n",
    "For this reason, we recommend training your own AE (Task A: Aspect Extraction) system using this notebook as a guide. For this task you, will need an annotated dataset. The sample dataset used here deals with hotel reviews and includes various annotated aspects like Hotel, Service, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRfXHyvPrn2a"
   },
   "source": [
    "❗ To understand and adapt this Notebook for your own use case, we expect a basic understanding of these concepts:\n",
    "\n",
    "- The task of ABSA\n",
    "- Fine-tuning\n",
    "- Language Models\n",
    "- Python and frequently used libraries (HuggingFace Transformers, FLAIR, scikit-learn, etc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x6NrY4Hrn2b"
   },
   "source": [
    "#### Installing the Dependencies\n",
    "\n",
    "We will first install all the libraries needed to run this notebook, this might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "H9dMvHrHrn2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flair in /home/ubuntu/venv/lib/python3.10/site-packages (0.15.1)\n",
      "Requirement already satisfied: transformers in /home/ubuntu/venv/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: torch in /home/ubuntu/venv/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/venv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: matplotlib in /home/ubuntu/venv/lib/python3.10/site-packages (3.10.3)\n",
      "Requirement already satisfied: ipymarkup in /home/ubuntu/venv/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/venv/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: statistics in /home/ubuntu/venv/lib/python3.10/site-packages (1.0.3.5)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/venv/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (0.2.0)\n",
      "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (0.4.2)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (1.0.9)\n",
      "Requirement already satisfied: gdown>=4.4.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (5.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (2024.11.6)\n",
      "Requirement already satisfied: ftfy>=6.1.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (6.3.1)\n",
      "Requirement already satisfied: bioc<3.0.0,>=2.0.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (2.1)\n",
      "Requirement already satisfied: more-itertools>=8.13.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (10.7.0)\n",
      "Requirement already satisfied: lxml>=4.8.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (5.4.0)\n",
      "Requirement already satisfied: pptree>=3.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (0.33.0)\n",
      "Requirement already satisfied: conllu<5.0.0,>=4.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (4.5.3)\n",
      "Requirement already satisfied: mpld3>=0.3 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (0.5.10)\n",
      "Requirement already satisfied: tabulate>=0.8.10 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (0.9.0)\n",
      "Requirement already satisfied: boto3>=1.20.27 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (1.38.40)\n",
      "Requirement already satisfied: sqlitedict>=2.0.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (2.1.0)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (1.2.18)\n",
      "Requirement already satisfied: wikipedia-api>=0.5.7 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (0.8.1)\n",
      "Requirement already satisfied: segtok>=1.5.11 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (1.5.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/venv/lib/python3.10/site-packages (from flair) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/ubuntu/venv/lib/python3.10/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: intervaltree>=3 in /home/ubuntu/venv/lib/python3.10/site-packages (from ipymarkup) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: docutils>=0.3 in /home/ubuntu/venv/lib/python3.10/site-packages (from statistics) (0.21.2)\n",
      "Requirement already satisfied: jsonlines>=1.2.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from bioc<3.0.0,>=2.0.0->flair) (4.0.0)\n",
      "Requirement already satisfied: docopt in /home/ubuntu/venv/lib/python3.10/site-packages (from bioc<3.0.0,>=2.0.0->flair) (0.6.2)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from boto3>=1.20.27->flair) (0.13.0)\n",
      "Requirement already satisfied: botocore<1.39.0,>=1.38.40 in /home/ubuntu/venv/lib/python3.10/site-packages (from boto3>=1.20.27->flair) (1.38.40)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from boto3>=1.20.27->flair) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/ubuntu/venv/lib/python3.10/site-packages (from deprecated>=1.2.13->flair) (1.17.2)\n",
      "Requirement already satisfied: wcwidth in /home/ubuntu/venv/lib/python3.10/site-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ubuntu/venv/lib/python3.10/site-packages (from gdown>=4.4.0->flair) (4.13.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/ubuntu/venv/lib/python3.10/site-packages (from huggingface-hub>=0.10.0->flair) (1.1.4)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from intervaltree>=3->ipymarkup) (2.4.0)\n",
      "Requirement already satisfied: six in /home/ubuntu/venv/lib/python3.10/site-packages (from langdetect>=1.0.9->flair) (1.17.0)\n",
      "Requirement already satisfied: protobuf in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (6.31.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/venv/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/venv/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/venv/lib/python3.10/site-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (25.3.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/ubuntu/venv/lib/python3.10/site-packages (from transformers) (1.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ubuntu/venv/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/ubuntu/venv/lib/python3.10/site-packages (from requests->transformers) (1.7.1)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/venv/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers) (7.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install flair transformers torch pandas matplotlib ipymarkup scikit-learn statistics tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4hQpY_Hrn2c"
   },
   "source": [
    "## Section 1: Fine-tuning a Model with your annotated dataset\n",
    "\n",
    "In this section, we will cover how you can fine-tune models for the task of ABSA from scratch using a few tools like transformers, the FLAIR-NLP toolkit, etc.\n",
    "As detailed above, ABSA consists of two tasks Aspect Extraction (Task A) and Sentiment Classification (Task B), let's look into Task A first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjFSoh0Drn2c"
   },
   "source": [
    "### Task A: Aspect Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFVSE4lBrn2c"
   },
   "source": [
    "The first and hardest task of ABSA, involves finding interesting aspects in unstructured text. The aspects can be a single word or a large phrase or named entity. This makes the task more difficult since there is no standard word length or limits for the aspects.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXfPn63_rn2c"
   },
   "source": [
    "#### A.1 Loading and checking your Data\n",
    "\n",
    "Now we will load our annotated dataset and do some quick checks to see how it looks. We have fine-tuned on our sample dataset. \n",
    "For this task, we need our dataset to be in the **.txt format**. Our original dataset was in **.xml format**. That is why we added the following two code cells to transform it to **.txt format**. The third code cell cleans our dataset to get best results. \n",
    "\n",
    "To train on your data, replace the paths of the files with your personal created dataset. Check what format your dataset is and based on that, follow the instructions in the following code cells to know which cells to run and which to ignore. Otherwise, you might run into issues!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from this code cell and run all of the following if your dataset is in .xml format\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    # Simple tokenizer: splits words and punctuation\n",
    "    return re.findall(r'\\w+|[^\\w\\s]', text)\n",
    "\n",
    "def convert_semeval_to_bio(xml_path, output_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        for review in root.findall(\"Review\"):\n",
    "            for sentence in review.findall(\".//sentence\"):\n",
    "                text_element = sentence.find(\"text\")\n",
    "                if text_element is None or text_element.text is None:\n",
    "                    continue\n",
    "\n",
    "                text = text_element.text.strip()\n",
    "                tokens = tokenize(text)\n",
    "                labels = [\"O\"] * len(tokens)\n",
    "\n",
    "                # Character offset to token mapping\n",
    "                char_to_token_idx = []\n",
    "                char_index = 0\n",
    "                for token in tokens:\n",
    "                    start_idx = text.find(token, char_index)\n",
    "                    end_idx = start_idx + len(token)\n",
    "                    char_to_token_idx.append((start_idx, end_idx))\n",
    "                    char_index = end_idx\n",
    "\n",
    "                opinions = sentence.find(\"Opinions\")\n",
    "                if opinions is not None:\n",
    "                    for opinion in opinions.findall(\"Opinion\"):\n",
    "                        target = opinion.attrib[\"target\"]\n",
    "                        if target == \"NULL\":\n",
    "                            continue  # Skip implicit aspect targets\n",
    "\n",
    "                        category = opinion.attrib[\"category\"]\n",
    "                        base_category = category.split(\"#\")[0]  # e.g., \"ROOMS_AMENITIES\"\n",
    "\n",
    "                        start = int(opinion.attrib[\"from\"])\n",
    "                        end = int(opinion.attrib[\"to\"])\n",
    "\n",
    "                        # Find matching tokens\n",
    "                        target_token_indexes = []\n",
    "                        for i, (char_start, char_end) in enumerate(char_to_token_idx):\n",
    "                            if char_start >= start and char_end <= end:\n",
    "                                target_token_indexes.append(i)\n",
    "\n",
    "                        if not target_token_indexes:\n",
    "                            continue\n",
    "\n",
    "                        # Tag tokens using BIO format with category\n",
    "                        labels[target_token_indexes[0]] = f\"B-{base_category}\"\n",
    "                        for i in target_token_indexes[1:]:\n",
    "                            labels[i] = f\"I-{base_category}\"\n",
    "\n",
    "                # Write sentence in CoNLL format\n",
    "                for token, label in zip(tokens, labels):\n",
    "                    out_file.write(f\"{token}\\t{label}\\n\")\n",
    "                out_file.write(\"\\n\")  # Sentence boundary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_semeval_to_bio(\"AR_Hotels_Train_SB1.xml\", \"iob_output_new.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code cell cleans our dataset for better training results\n",
    "input_file = \"iob_output_new.txt\"\n",
    "output_file = \"iob_output_relabelled.txt\"\n",
    "\n",
    "# Define labels you want to remove\n",
    "labels_to_remove = {\"B-ROOMS_AMENITIES\", \"I-ROOMS_AMENITIES\", \"B-FACILITIES\", \"I-FACILITIES\"}\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        if line.strip() == \"\":\n",
    "            outfile.write(\"\\n\")  # preserve blank lines\n",
    "            continue\n",
    "\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            token, label = parts\n",
    "            if label != \"O\":\n",
    "                # Remove anything after #\n",
    "                prefix, tag = label.split(\"-\", 1)\n",
    "                base_tag = tag.split(\"#\")[0]\n",
    "                label = f\"{prefix}-{base_tag}\"\n",
    "              # If label contains ROOMS_AMENITIES, replace it with \"O\"\n",
    "        if label in labels_to_remove:\n",
    "                label = \"O\"\n",
    "        else:\n",
    "            # handle malformed lines (e.g., no tab)\n",
    "            outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أنصح</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>بالنوم</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>وليس</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>تناول</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الطعام</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Token Label\n",
       "0    أنصح     O\n",
       "1  بالنوم     O\n",
       "2    وليس     O\n",
       "3   تناول     O\n",
       "4  الطعام     O"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start from this code cell if your dataset is already in .txt format\n",
    "# Also run this code cell if you started with .xml format and ran he code cells above\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    'iob_output_relabelled.txt',\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=['Token', 'Label'],\n",
    "    keep_default_na=False,\n",
    "    skip_blank_lines=False\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yXz6Cggrn2d"
   },
   "source": [
    "As you can see, we have successfully loaded our data. The **token** column refers to the current token in question, the **Label** column refers to the label of the current token. There are 3 labels:\n",
    "\n",
    "- **B-ASPECT**: A token that marks the beginning of an aspect\n",
    "- **I-ASPECT**: A token that is inside an aspect\n",
    "- **O**: A token that is not part of any aspect\n",
    "\n",
    "This data format is called the IOB (Inside, Outside, Beginning) format, and this is how most aspect extraction datasets are stored.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hqBp6vkrn2d"
   },
   "source": [
    "Let's also split our data into a training, validation and test parts while we are at it.\n",
    "\n",
    "We first make a 80:20 split, and keep 80 percent of the data for training the model.\n",
    "\n",
    "From the 20 percent we wil divide it in half, and use 10 percent for validation and 10 percent for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3L75C3n3sizd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, shuffle=False)\n",
    "\n",
    "train_df.to_csv('data/train.txt', sep='\\t', header=False, index=False)\n",
    "val_df.to_csv('data/val.txt', sep='\\t', header=False, index=False)\n",
    "test_df.to_csv('data/test.txt', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5pABsEorn2e"
   },
   "source": [
    "#### A.2 Sequence Tagger with Flair-NLP: Loading Modules, Data & Defining Parameters\n",
    "\n",
    "[Flair-NLP](https://github.com/flairNLP/flair) is a widely used toolkit for training advanced sequence tagger models for various applications like Named Entity Recognition, Aspect Based Sentiment Analysis, etc. The library provides a variety of options to train your models like word embeddings, pre-trained transformers, conditional random fields (CRFs), etc. Please refer to the [documentation of FLAIR](https://flairnlp.github.io/docs/intro) for a more detailed overview of it's capabilities.\n",
    "\n",
    "In this particular example, we will use one of the options available in FLAIR to train our own Sequence Tagger using a pre-trained Transformer model.\n",
    "\n",
    "Let's begin by loading the necessary modules of Flair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "leU9e_77rn2e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import TransformerWordEmbeddings, WordEmbeddings, StackedEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.data import Sentence\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G26733LCrn2e"
   },
   "source": [
    "Now let's begin by loading out data into Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "l7BzU5b8rn2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:06:30,796 Reading data from data\n",
      "2025-06-25 15:06:30,798 Train: data/train.txt\n",
      "2025-06-25 15:06:30,799 Dev: data/val.txt\n",
      "2025-06-25 15:06:30,800 Test: data/test.txt\n",
      "Sentence[13]: \"أنصح بالنوم وليس تناول الطعام موقع مثالي للإقامة قبل رحلة طيران مبكرة .\" → [\"موقع\"/LOCATION]\n"
     ]
    }
   ],
   "source": [
    "columns = {0: 'text', 1: 'label'} # This specifies which column is the text and which column is the label. In our case, the text is in the first column and the label is in the second column.\n",
    "data_folder = Path('data') # This is the folder where your data is stored.\n",
    "corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train.txt',\n",
    "                              dev_file='val.txt',\n",
    "                              test_file='test.txt')\n",
    "\n",
    "print(corpus.train[0].to_tagged_string('label'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3-TG3H7rn2f"
   },
   "source": [
    "Now let's define a few variables for our training. These are some key parameters so some additional information about them is added in the comments. Be sure to read them so you can make appropriate choices for your setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IP_2Dsc_rn2f"
   },
   "outputs": [],
   "source": [
    "model_name = 'aubmindlab/bert-base-arabertv2' #This is the pre-trained model we are going to use. You can change this to any other model from the transformers library. To look for available models, you can visit https://huggingface.co/models\n",
    "fine_tune = True #With this Arabic model do not set fine-tune to false as your model will at the end not be able to train well. With this model, fine-tuning must be set to true. Fine-tuning results in better performance but requires more computational resources and time.\n",
    "hidden_size = 256 #This is the size of the hidden layer of the model. You can change this to any other value depending on the computational resources you have. If your training is taking too long, experiment with reducing this number.\n",
    "use_crf = True #With this model, we need crf to be set true, so that the model can look at the whole sentence and make sure labels follow logical patterns. It trains the model to look at and think about the flow of labels, so how they connect.\n",
    "output_model_path = 'ar_aspect_extraction_model' #This is the path where the trained model will be saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxWlWsf4rn2g"
   },
   "source": [
    "#### A.3 Sequence Tagger with Flair-NLP: Final Setup & Training\n",
    "\n",
    "Perfect, now let's setup all the parameters and details of our model to-be trained soon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "s8aGMnQNrn2g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:06:31,964 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "3830it [00:00, 37852.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:06:32,073 Dictionary created for label 'label' with 5 values: HOTEL (seen 1598 times), SERVICE (seen 1341 times), ROOMS (seen 867 times), LOCATION (seen 684 times), FOOD_DRINKS (seen 590 times)\n",
      "Dictionary with 5 tags: HOTEL, SERVICE, ROOMS, LOCATION, FOOD_DRINKS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:06:33,618 SequenceTagger predicts: Dictionary with 21 tags: O, S-HOTEL, B-HOTEL, E-HOTEL, I-HOTEL, S-SERVICE, B-SERVICE, E-SERVICE, I-SERVICE, S-ROOMS, B-ROOMS, E-ROOMS, I-ROOMS, S-LOCATION, B-LOCATION, E-LOCATION, I-LOCATION, S-FOOD_DRINKS, B-FOOD_DRINKS, E-FOOD_DRINKS, I-FOOD_DRINKS\n"
     ]
    }
   ],
   "source": [
    "# 1. Which column do we want to predict?\n",
    "label_type = 'label'\n",
    "\n",
    "# 2. Make the label dictionary from the corpus, i.e. a mapping of labels to numbers\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type, )\n",
    "print(label_dict)\n",
    "\n",
    "# 3. Initialize fine-tuneable transformer embeddings WITH document context. These are the embeddings that will be used for classifying the tokens into aspects.\n",
    "embeddings = TransformerWordEmbeddings(model = model_name,\n",
    "                                       layers=\"-1\", #ONLY USE THE LAST LAYER (common practice, but can experiment with other layers)\n",
    "                                       subtoken_pooling=\"first\",\n",
    "                                       fine_tune= fine_tune,\n",
    "                                       use_context=True, #document context is considered during the embedding process (surrounding words, ...)\n",
    "                                       )\n",
    "\n",
    "# 4. Initialize our sequence tagger, you can experiment with the hyperparameters here to suit your needs. Some tinkering might help you reach better performance for your dataset.\n",
    "tagger = SequenceTagger(hidden_size=hidden_size,\n",
    "                        embeddings=embeddings,\n",
    "                        tag_dictionary=label_dict,\n",
    "                        tag_type=label_type,\n",
    "                        use_crf=use_crf,\n",
    "                        use_rnn=False,\n",
    "                        reproject_embeddings=False,\n",
    "                        )\n",
    "\n",
    "# 5. Initialize trainer\n",
    "trainer = ModelTrainer(tagger, corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xCKjNMXrn2g"
   },
   "source": [
    "Great, everything seems to be ready, it's time to start training. Remember, this can take quite a while, so grab yourself a cup of coffee in the meantime!\n",
    "\n",
    "If you have GPU available, switch from CPU to GPU! CPU requires a lot of time and might crash if the training set and model are big!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oiQVIwi8rn2g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:06:33,630 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:06:33,631 Model: \"SequenceTagger(\n",
      "  (embeddings): TransformerWordEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(64001, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSdpaSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (linear): Linear(in_features=768, out_features=23, bias=True)\n",
      "  (loss_function): ViterbiLoss()\n",
      "  (crf): CRF()\n",
      ")\"\n",
      "2025-06-25 15:06:33,631 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:06:33,632 Corpus: 3830 train + 468 dev + 506 test sentences\n",
      "2025-06-25 15:06:33,633 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:06:33,633 Train:  3830 sentences\n",
      "2025-06-25 15:06:33,634         (train_with_dev=False, train_with_test=False)\n",
      "2025-06-25 15:06:33,637 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:06:33,638 Training Params:\n",
      "2025-06-25 15:06:33,638  - learning_rate: \"5e-06\" \n",
      "2025-06-25 15:06:33,640  - mini_batch_size: \"4\"\n",
      "2025-06-25 15:06:33,640  - max_epochs: \"15\"\n",
      "2025-06-25 15:06:33,641  - shuffle: \"True\"\n",
      "2025-06-25 15:06:33,642 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:06:33,643 Plugins:\n",
      "2025-06-25 15:06:33,644  - LinearScheduler | warmup_fraction: '0.1'\n",
      "2025-06-25 15:06:33,644 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:06:33,645 Final evaluation on model after last epoch (final-model.pt)\n",
      "2025-06-25 15:06:33,645  - metric: \"('micro avg', 'f1-score')\"\n",
      "2025-06-25 15:06:33,646 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:06:33,646 Computation:\n",
      "2025-06-25 15:06:33,647  - compute on device: cuda:0\n",
      "2025-06-25 15:06:33,648  - embedding storage: none\n",
      "2025-06-25 15:06:33,648 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:06:33,649 Model training base path: \"ar_aspect_extraction_model\"\n",
      "2025-06-25 15:06:33,649 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:06:33,650 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/lib/python3.10/site-packages/flair/trainers/trainer.py:545: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp and flair.device.type != \"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:06:57,493 epoch 1 - iter 95/958 - loss 4.74335731 - time (sec): 23.84 - samples/sec: 343.68 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 15:07:20,666 epoch 1 - iter 190/958 - loss 4.50830923 - time (sec): 47.02 - samples/sec: 360.54 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:07:43,517 epoch 1 - iter 285/958 - loss 4.12774296 - time (sec): 69.87 - samples/sec: 363.25 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:08:06,566 epoch 1 - iter 380/958 - loss 3.63167764 - time (sec): 92.91 - samples/sec: 368.05 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:08:30,339 epoch 1 - iter 475/958 - loss 3.17818836 - time (sec): 116.69 - samples/sec: 371.97 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:08:53,423 epoch 1 - iter 570/958 - loss 2.84376938 - time (sec): 139.77 - samples/sec: 371.45 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:09:17,229 epoch 1 - iter 665/958 - loss 2.56555691 - time (sec): 163.58 - samples/sec: 374.10 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:09:41,223 epoch 1 - iter 760/958 - loss 2.35880284 - time (sec): 187.57 - samples/sec: 373.29 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:10:05,284 epoch 1 - iter 855/958 - loss 2.19862903 - time (sec): 211.63 - samples/sec: 371.89 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:10:28,923 epoch 1 - iter 950/958 - loss 2.06898567 - time (sec): 235.27 - samples/sec: 370.68 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:10:30,821 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:10:30,822 EPOCH 1 done: loss 2.0601 - lr: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:10:40,574 DEV : loss 0.5422455668449402 - f1-score (micro avg)  0.0\n",
      "2025-06-25 15:10:40,586 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:11:04,735 epoch 2 - iter 95/958 - loss 0.83747329 - time (sec): 24.15 - samples/sec: 362.52 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:11:28,123 epoch 2 - iter 190/958 - loss 0.81790975 - time (sec): 47.54 - samples/sec: 362.23 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:11:51,535 epoch 2 - iter 285/958 - loss 0.80646149 - time (sec): 70.95 - samples/sec: 360.84 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:12:15,517 epoch 2 - iter 380/958 - loss 0.79791180 - time (sec): 94.93 - samples/sec: 365.08 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:12:39,507 epoch 2 - iter 475/958 - loss 0.79196620 - time (sec): 118.92 - samples/sec: 366.60 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:13:03,808 epoch 2 - iter 570/958 - loss 0.78539934 - time (sec): 143.22 - samples/sec: 368.03 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:13:27,730 epoch 2 - iter 665/958 - loss 0.78145846 - time (sec): 167.14 - samples/sec: 369.90 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:13:51,059 epoch 2 - iter 760/958 - loss 0.78118049 - time (sec): 190.47 - samples/sec: 367.96 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:14:14,641 epoch 2 - iter 855/958 - loss 0.77540544 - time (sec): 214.05 - samples/sec: 368.40 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:14:38,132 epoch 2 - iter 950/958 - loss 0.77213485 - time (sec): 237.54 - samples/sec: 367.24 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:14:39,980 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:14:39,981 EPOCH 2 done: loss 0.7714 - lr: 0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:14:49,830 DEV : loss 0.45885029435157776 - f1-score (micro avg)  0.0\n",
      "2025-06-25 15:14:49,846 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:15:13,201 epoch 3 - iter 95/958 - loss 0.72783033 - time (sec): 23.35 - samples/sec: 356.71 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:15:36,650 epoch 3 - iter 190/958 - loss 0.74129287 - time (sec): 46.80 - samples/sec: 358.89 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:16:00,759 epoch 3 - iter 285/958 - loss 0.74479853 - time (sec): 70.91 - samples/sec: 363.43 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:16:24,397 epoch 3 - iter 380/958 - loss 0.73420933 - time (sec): 94.55 - samples/sec: 363.29 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:16:48,217 epoch 3 - iter 475/958 - loss 0.72644078 - time (sec): 118.37 - samples/sec: 365.01 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:17:11,988 epoch 3 - iter 570/958 - loss 0.71364948 - time (sec): 142.14 - samples/sec: 363.59 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:17:35,797 epoch 3 - iter 665/958 - loss 0.70130244 - time (sec): 165.95 - samples/sec: 365.37 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:17:59,023 epoch 3 - iter 760/958 - loss 0.68964944 - time (sec): 189.17 - samples/sec: 365.55 - lr: 0.000005 - momentum: 0.000000\n",
      "2025-06-25 15:18:23,167 epoch 3 - iter 855/958 - loss 0.68077369 - time (sec): 213.32 - samples/sec: 365.70 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:18:47,132 epoch 3 - iter 950/958 - loss 0.67020985 - time (sec): 237.28 - samples/sec: 367.90 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:18:49,026 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:18:49,027 EPOCH 3 done: loss 0.6695 - lr: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:18:59,188 DEV : loss 0.29188379645347595 - f1-score (micro avg)  0.2851\n",
      "2025-06-25 15:18:59,200 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:19:23,344 epoch 4 - iter 95/958 - loss 0.54777300 - time (sec): 24.14 - samples/sec: 372.88 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:19:47,238 epoch 4 - iter 190/958 - loss 0.54827032 - time (sec): 48.04 - samples/sec: 364.52 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:20:10,978 epoch 4 - iter 285/958 - loss 0.55710297 - time (sec): 71.78 - samples/sec: 368.62 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:20:34,331 epoch 4 - iter 380/958 - loss 0.55303907 - time (sec): 95.13 - samples/sec: 369.47 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:20:57,453 epoch 4 - iter 475/958 - loss 0.56179460 - time (sec): 118.25 - samples/sec: 366.75 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:21:21,139 epoch 4 - iter 570/958 - loss 0.55867546 - time (sec): 141.94 - samples/sec: 365.16 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:21:45,179 epoch 4 - iter 665/958 - loss 0.55401689 - time (sec): 165.98 - samples/sec: 365.59 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:22:08,726 epoch 4 - iter 760/958 - loss 0.55457803 - time (sec): 189.52 - samples/sec: 365.62 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:22:32,854 epoch 4 - iter 855/958 - loss 0.55337751 - time (sec): 213.65 - samples/sec: 366.19 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:22:56,563 epoch 4 - iter 950/958 - loss 0.55146408 - time (sec): 237.36 - samples/sec: 367.62 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:22:58,387 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:22:58,387 EPOCH 4 done: loss 0.5524 - lr: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:23:08,239 DEV : loss 0.24633224308490753 - f1-score (micro avg)  0.4894\n",
      "2025-06-25 15:23:08,252 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:23:31,827 epoch 5 - iter 95/958 - loss 0.54777000 - time (sec): 23.57 - samples/sec: 378.13 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:23:55,680 epoch 5 - iter 190/958 - loss 0.53680774 - time (sec): 47.43 - samples/sec: 370.05 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:24:19,302 epoch 5 - iter 285/958 - loss 0.52533352 - time (sec): 71.05 - samples/sec: 369.27 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:24:42,719 epoch 5 - iter 380/958 - loss 0.52339930 - time (sec): 94.47 - samples/sec: 368.38 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:25:06,167 epoch 5 - iter 475/958 - loss 0.52292998 - time (sec): 117.91 - samples/sec: 365.39 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:25:30,044 epoch 5 - iter 570/958 - loss 0.51953858 - time (sec): 141.79 - samples/sec: 368.59 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:25:53,668 epoch 5 - iter 665/958 - loss 0.51700013 - time (sec): 165.41 - samples/sec: 369.04 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:26:17,250 epoch 5 - iter 760/958 - loss 0.51503712 - time (sec): 189.00 - samples/sec: 369.62 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:26:40,449 epoch 5 - iter 855/958 - loss 0.51354010 - time (sec): 212.20 - samples/sec: 368.38 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:27:04,163 epoch 5 - iter 950/958 - loss 0.51262490 - time (sec): 235.91 - samples/sec: 370.22 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:27:05,887 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:27:05,888 EPOCH 5 done: loss 0.5126 - lr: 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:27:15,777 DEV : loss 0.21738246083259583 - f1-score (micro avg)  0.5719\n",
      "2025-06-25 15:27:15,789 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:27:39,489 epoch 6 - iter 95/958 - loss 0.48959188 - time (sec): 23.70 - samples/sec: 355.60 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:28:02,839 epoch 6 - iter 190/958 - loss 0.47201740 - time (sec): 47.05 - samples/sec: 353.68 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:28:27,148 epoch 6 - iter 285/958 - loss 0.46674163 - time (sec): 71.36 - samples/sec: 364.67 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:28:50,915 epoch 6 - iter 380/958 - loss 0.46197053 - time (sec): 95.12 - samples/sec: 362.81 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:29:14,672 epoch 6 - iter 475/958 - loss 0.46721947 - time (sec): 118.88 - samples/sec: 366.95 - lr: 0.000004 - momentum: 0.000000\n",
      "2025-06-25 15:29:38,362 epoch 6 - iter 570/958 - loss 0.46794166 - time (sec): 142.57 - samples/sec: 367.72 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:30:02,203 epoch 6 - iter 665/958 - loss 0.47013956 - time (sec): 166.41 - samples/sec: 368.30 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:30:25,883 epoch 6 - iter 760/958 - loss 0.47537377 - time (sec): 190.09 - samples/sec: 367.76 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:30:49,679 epoch 6 - iter 855/958 - loss 0.47222962 - time (sec): 213.89 - samples/sec: 367.45 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:31:12,792 epoch 6 - iter 950/958 - loss 0.47161329 - time (sec): 237.00 - samples/sec: 368.23 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:31:14,665 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:31:14,666 EPOCH 6 done: loss 0.4723 - lr: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:31:24,547 DEV : loss 0.20599065721035004 - f1-score (micro avg)  0.6104\n",
      "2025-06-25 15:31:24,560 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:31:48,449 epoch 7 - iter 95/958 - loss 0.45428830 - time (sec): 23.89 - samples/sec: 384.79 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:32:12,054 epoch 7 - iter 190/958 - loss 0.46683448 - time (sec): 47.49 - samples/sec: 366.88 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:32:35,586 epoch 7 - iter 285/958 - loss 0.46890756 - time (sec): 71.02 - samples/sec: 368.75 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:32:59,609 epoch 7 - iter 380/958 - loss 0.46803170 - time (sec): 95.05 - samples/sec: 366.13 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:33:23,444 epoch 7 - iter 475/958 - loss 0.46155024 - time (sec): 118.88 - samples/sec: 365.88 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:33:46,857 epoch 7 - iter 570/958 - loss 0.46289557 - time (sec): 142.30 - samples/sec: 367.77 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:34:10,373 epoch 7 - iter 665/958 - loss 0.46467673 - time (sec): 165.81 - samples/sec: 369.63 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:34:33,984 epoch 7 - iter 760/958 - loss 0.46456034 - time (sec): 189.42 - samples/sec: 371.52 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:34:57,932 epoch 7 - iter 855/958 - loss 0.46816905 - time (sec): 213.37 - samples/sec: 369.88 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:35:21,524 epoch 7 - iter 950/958 - loss 0.46642442 - time (sec): 236.96 - samples/sec: 368.99 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:35:23,313 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:35:23,314 EPOCH 7 done: loss 0.4661 - lr: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:35:33,186 DEV : loss 0.19351017475128174 - f1-score (micro avg)  0.627\n",
      "2025-06-25 15:35:33,198 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:35:56,520 epoch 8 - iter 95/958 - loss 0.44890301 - time (sec): 23.32 - samples/sec: 369.55 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:36:20,040 epoch 8 - iter 190/958 - loss 0.42988344 - time (sec): 46.84 - samples/sec: 378.56 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:36:43,128 epoch 8 - iter 285/958 - loss 0.44273606 - time (sec): 69.93 - samples/sec: 372.85 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:37:06,958 epoch 8 - iter 380/958 - loss 0.44641878 - time (sec): 93.76 - samples/sec: 373.98 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:37:30,616 epoch 8 - iter 475/958 - loss 0.44737251 - time (sec): 117.42 - samples/sec: 373.41 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:37:53,928 epoch 8 - iter 570/958 - loss 0.45097680 - time (sec): 140.73 - samples/sec: 370.44 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:38:17,232 epoch 8 - iter 665/958 - loss 0.45098887 - time (sec): 164.03 - samples/sec: 369.54 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:38:40,941 epoch 8 - iter 760/958 - loss 0.45468096 - time (sec): 187.74 - samples/sec: 370.07 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:39:04,540 epoch 8 - iter 855/958 - loss 0.45041149 - time (sec): 211.34 - samples/sec: 369.89 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:39:28,669 epoch 8 - iter 950/958 - loss 0.44527584 - time (sec): 235.47 - samples/sec: 370.44 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:39:30,622 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:39:30,623 EPOCH 8 done: loss 0.4452 - lr: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:39:40,530 DEV : loss 0.18985572457313538 - f1-score (micro avg)  0.6386\n",
      "2025-06-25 15:39:40,542 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:40:04,335 epoch 9 - iter 95/958 - loss 0.41989750 - time (sec): 23.79 - samples/sec: 361.82 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:40:27,949 epoch 9 - iter 190/958 - loss 0.43007951 - time (sec): 47.40 - samples/sec: 364.58 - lr: 0.000003 - momentum: 0.000000\n",
      "2025-06-25 15:40:51,738 epoch 9 - iter 285/958 - loss 0.42916392 - time (sec): 71.19 - samples/sec: 368.25 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:41:15,262 epoch 9 - iter 380/958 - loss 0.42802421 - time (sec): 94.72 - samples/sec: 368.85 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:41:38,845 epoch 9 - iter 475/958 - loss 0.42713881 - time (sec): 118.30 - samples/sec: 372.48 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:42:02,438 epoch 9 - iter 570/958 - loss 0.43728564 - time (sec): 141.89 - samples/sec: 371.85 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:42:26,154 epoch 9 - iter 665/958 - loss 0.43449829 - time (sec): 165.61 - samples/sec: 368.85 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:42:50,008 epoch 9 - iter 760/958 - loss 0.43306223 - time (sec): 189.46 - samples/sec: 368.15 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:43:13,737 epoch 9 - iter 855/958 - loss 0.43183833 - time (sec): 213.19 - samples/sec: 369.57 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:43:37,629 epoch 9 - iter 950/958 - loss 0.43388096 - time (sec): 237.09 - samples/sec: 368.36 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:43:39,499 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:43:39,500 EPOCH 9 done: loss 0.4346 - lr: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:43:49,391 DEV : loss 0.19528019428253174 - f1-score (micro avg)  0.631\n",
      "2025-06-25 15:43:49,404 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:44:13,472 epoch 10 - iter 95/958 - loss 0.43829418 - time (sec): 24.07 - samples/sec: 376.25 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:44:37,477 epoch 10 - iter 190/958 - loss 0.43777032 - time (sec): 48.07 - samples/sec: 387.40 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:45:01,602 epoch 10 - iter 285/958 - loss 0.43491762 - time (sec): 72.20 - samples/sec: 377.74 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:45:25,402 epoch 10 - iter 380/958 - loss 0.43112592 - time (sec): 96.00 - samples/sec: 370.42 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:45:48,721 epoch 10 - iter 475/958 - loss 0.42862070 - time (sec): 119.32 - samples/sec: 367.08 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:46:12,753 epoch 10 - iter 570/958 - loss 0.43255714 - time (sec): 143.35 - samples/sec: 369.00 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:46:36,183 epoch 10 - iter 665/958 - loss 0.43116819 - time (sec): 166.78 - samples/sec: 367.69 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:46:59,622 epoch 10 - iter 760/958 - loss 0.43367827 - time (sec): 190.22 - samples/sec: 369.24 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:47:22,533 epoch 10 - iter 855/958 - loss 0.43499487 - time (sec): 213.13 - samples/sec: 367.15 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:47:46,070 epoch 10 - iter 950/958 - loss 0.43332887 - time (sec): 236.66 - samples/sec: 368.02 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:47:48,104 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:47:48,105 EPOCH 10 done: loss 0.4327 - lr: 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:47:58,006 DEV : loss 0.1861683428287506 - f1-score (micro avg)  0.6287\n",
      "2025-06-25 15:47:58,018 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:48:21,396 epoch 11 - iter 95/958 - loss 0.41793465 - time (sec): 23.38 - samples/sec: 377.81 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:48:45,096 epoch 11 - iter 190/958 - loss 0.41545066 - time (sec): 47.08 - samples/sec: 376.28 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:49:08,694 epoch 11 - iter 285/958 - loss 0.42037846 - time (sec): 70.67 - samples/sec: 372.20 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:49:31,998 epoch 11 - iter 380/958 - loss 0.41726213 - time (sec): 93.98 - samples/sec: 366.02 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:49:55,525 epoch 11 - iter 475/958 - loss 0.41577611 - time (sec): 117.51 - samples/sec: 368.80 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:50:19,104 epoch 11 - iter 570/958 - loss 0.41294264 - time (sec): 141.08 - samples/sec: 371.31 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:50:42,462 epoch 11 - iter 665/958 - loss 0.41638881 - time (sec): 164.44 - samples/sec: 369.13 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:51:06,649 epoch 11 - iter 760/958 - loss 0.41541868 - time (sec): 188.63 - samples/sec: 370.28 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:51:30,665 epoch 11 - iter 855/958 - loss 0.41319887 - time (sec): 212.65 - samples/sec: 370.04 - lr: 0.000002 - momentum: 0.000000\n",
      "2025-06-25 15:51:54,458 epoch 11 - iter 950/958 - loss 0.41553815 - time (sec): 236.44 - samples/sec: 368.80 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:51:56,410 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:51:56,410 EPOCH 11 done: loss 0.4153 - lr: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:52:06,337 DEV : loss 0.1868019551038742 - f1-score (micro avg)  0.6372\n",
      "2025-06-25 15:52:06,349 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:52:30,319 epoch 12 - iter 95/958 - loss 0.40533281 - time (sec): 23.97 - samples/sec: 373.70 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:52:53,975 epoch 12 - iter 190/958 - loss 0.41307741 - time (sec): 47.62 - samples/sec: 376.13 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:53:17,768 epoch 12 - iter 285/958 - loss 0.41290529 - time (sec): 71.42 - samples/sec: 367.15 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:53:41,281 epoch 12 - iter 380/958 - loss 0.41531157 - time (sec): 94.93 - samples/sec: 368.84 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:54:04,668 epoch 12 - iter 475/958 - loss 0.42192527 - time (sec): 118.32 - samples/sec: 368.97 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:54:28,716 epoch 12 - iter 570/958 - loss 0.41735658 - time (sec): 142.36 - samples/sec: 368.12 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:54:52,485 epoch 12 - iter 665/958 - loss 0.42161563 - time (sec): 166.13 - samples/sec: 367.67 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:55:16,037 epoch 12 - iter 760/958 - loss 0.41902626 - time (sec): 189.69 - samples/sec: 368.81 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:55:39,762 epoch 12 - iter 855/958 - loss 0.42022721 - time (sec): 213.41 - samples/sec: 369.10 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:56:03,348 epoch 12 - iter 950/958 - loss 0.41839603 - time (sec): 237.00 - samples/sec: 368.28 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:56:05,242 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 15:56:05,243 EPOCH 12 done: loss 0.4186 - lr: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:56:15,403 DEV : loss 0.18906718492507935 - f1-score (micro avg)  0.6485\n",
      "2025-06-25 15:56:15,414 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 15:56:39,343 epoch 13 - iter 95/958 - loss 0.38809031 - time (sec): 23.93 - samples/sec: 387.93 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:57:02,643 epoch 13 - iter 190/958 - loss 0.39886227 - time (sec): 47.23 - samples/sec: 371.15 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:57:26,338 epoch 13 - iter 285/958 - loss 0.40109106 - time (sec): 70.92 - samples/sec: 369.65 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:57:50,188 epoch 13 - iter 380/958 - loss 0.40747738 - time (sec): 94.77 - samples/sec: 369.60 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:58:13,477 epoch 13 - iter 475/958 - loss 0.40958263 - time (sec): 118.06 - samples/sec: 371.89 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:58:37,177 epoch 13 - iter 570/958 - loss 0.40890613 - time (sec): 141.76 - samples/sec: 374.57 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:59:00,799 epoch 13 - iter 665/958 - loss 0.40860771 - time (sec): 165.38 - samples/sec: 370.85 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:59:24,099 epoch 13 - iter 760/958 - loss 0.40638134 - time (sec): 188.68 - samples/sec: 371.49 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 15:59:48,014 epoch 13 - iter 855/958 - loss 0.41065170 - time (sec): 212.60 - samples/sec: 371.62 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 16:00:11,249 epoch 13 - iter 950/958 - loss 0.41117273 - time (sec): 235.83 - samples/sec: 370.04 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 16:00:13,156 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 16:00:13,157 EPOCH 13 done: loss 0.4109 - lr: 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 16:00:23,009 DEV : loss 0.19430778920650482 - f1-score (micro avg)  0.635\n",
      "2025-06-25 16:00:23,021 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 16:00:46,517 epoch 14 - iter 95/958 - loss 0.41432389 - time (sec): 23.49 - samples/sec: 355.87 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 16:01:09,912 epoch 14 - iter 190/958 - loss 0.40303685 - time (sec): 46.89 - samples/sec: 363.43 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 16:01:33,175 epoch 14 - iter 285/958 - loss 0.40287498 - time (sec): 70.15 - samples/sec: 369.94 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 16:01:56,737 epoch 14 - iter 380/958 - loss 0.41192216 - time (sec): 93.71 - samples/sec: 366.92 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 16:02:20,413 epoch 14 - iter 475/958 - loss 0.40835199 - time (sec): 117.39 - samples/sec: 362.84 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 16:02:44,128 epoch 14 - iter 570/958 - loss 0.40701100 - time (sec): 141.11 - samples/sec: 365.43 - lr: 0.000001 - momentum: 0.000000\n",
      "2025-06-25 16:03:07,664 epoch 14 - iter 665/958 - loss 0.40701795 - time (sec): 164.64 - samples/sec: 365.59 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:03:31,468 epoch 14 - iter 760/958 - loss 0.40670064 - time (sec): 188.45 - samples/sec: 366.88 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:03:55,164 epoch 14 - iter 855/958 - loss 0.40927179 - time (sec): 212.14 - samples/sec: 369.01 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:04:19,228 epoch 14 - iter 950/958 - loss 0.40947482 - time (sec): 236.21 - samples/sec: 369.82 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:04:21,100 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 16:04:21,102 EPOCH 14 done: loss 0.4095 - lr: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 16:04:30,999 DEV : loss 0.19066837430000305 - f1-score (micro avg)  0.6398\n",
      "2025-06-25 16:04:31,011 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 16:04:54,734 epoch 15 - iter 95/958 - loss 0.40097827 - time (sec): 23.72 - samples/sec: 364.44 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:05:18,765 epoch 15 - iter 190/958 - loss 0.40679064 - time (sec): 47.75 - samples/sec: 368.25 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:05:42,756 epoch 15 - iter 285/958 - loss 0.40122948 - time (sec): 71.74 - samples/sec: 369.05 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:06:06,119 epoch 15 - iter 380/958 - loss 0.39763154 - time (sec): 95.11 - samples/sec: 369.27 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:06:29,810 epoch 15 - iter 475/958 - loss 0.40480834 - time (sec): 118.80 - samples/sec: 370.37 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:06:53,094 epoch 15 - iter 570/958 - loss 0.40299096 - time (sec): 142.08 - samples/sec: 367.70 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:07:17,131 epoch 15 - iter 665/958 - loss 0.40527752 - time (sec): 166.12 - samples/sec: 368.76 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:07:40,784 epoch 15 - iter 760/958 - loss 0.40548052 - time (sec): 189.77 - samples/sec: 368.28 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:08:04,287 epoch 15 - iter 855/958 - loss 0.40423713 - time (sec): 213.27 - samples/sec: 368.21 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:08:27,686 epoch 15 - iter 950/958 - loss 0.40620875 - time (sec): 236.67 - samples/sec: 368.94 - lr: 0.000000 - momentum: 0.000000\n",
      "2025-06-25 16:08:29,559 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 16:08:29,560 EPOCH 15 done: loss 0.4061 - lr: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 16:08:39,444 DEV : loss 0.19247663021087646 - f1-score (micro avg)  0.6339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 16:08:42,069 ----------------------------------------------------------------------------------------------------\n",
      "2025-06-25 16:08:42,071 Testing using last state of model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 32/32 [00:09<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-25 16:08:51,903 \n",
      "Results:\n",
      "- F-score (micro) 0.6282\n",
      "- F-score (macro) 0.6231\n",
      "- Accuracy 0.4821\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       HOTEL     0.6250    0.6114    0.6181       229\n",
      "     SERVICE     0.6786    0.7268    0.7018       183\n",
      "       ROOMS     0.5490    0.7568    0.6364       111\n",
      "    LOCATION     0.4234    0.4747    0.4476        99\n",
      " FOOD_DRINKS     0.6974    0.7260    0.7114        73\n",
      "\n",
      "   micro avg     0.6013    0.6576    0.6282       695\n",
      "   macro avg     0.5947    0.6591    0.6231       695\n",
      "weighted avg     0.6059    0.6576    0.6286       695\n",
      "\n",
      "2025-06-25 16:08:51,903 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.6281786941580756}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fine_tune(output_model_path,\n",
    "                  learning_rate=5.0e-6, # Can be tuned for your data\n",
    "                  mini_batch_size=4, # Should be adjusted based on your computation resources. If the code crashes due to memory errors, reduce it. If you have a big GPU, you can increase it to speed up training.\n",
    "                  mini_batch_chunk_size=1,  # Remove this parameter to speed up computation if you have a big GPU\n",
    "                  max_epochs=15, # You can adjust the training epochs. The higher the number of epochs is, the better your model trains, yet it takes more time!\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVUm95n9rn2g"
   },
   "source": [
    "#### A.4 Testing the Model\n",
    "\n",
    "\n",
    "Our model is ready, want to test it on a random sentence? Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lybkgpOJrn2g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence[16]: \"موقع الفندق ممتاز وقريب من جميع الخدمات، لكن مستوى النظافة في الغرف كان غير مرضٍ.\" → [\"موقع\"/LOCATION, \"الغرف\"/ROOMS]\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('موقع الفندق ممتاز وقريب من جميع الخدمات، لكن مستوى النظافة في الغرف كان غير مرضٍ.')\n",
    "\n",
    "# predict aspect tags\n",
    "tagger.predict(sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMKxV4KArn2h"
   },
   "source": [
    "As, you can see, even with some conservative settings we are able to have a pretty good aspect extraction model!\n",
    "\n",
    "To make this model even better, you can try increasing the **hidden_size**.\n",
    "\n",
    "You can also further tune the hyper-parameters such as **learning_rate** since the optimal values can vary significantly depending on the model and data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "he6ynL8Srn2h"
   },
   "source": [
    "### Task B: Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5jhalvdrn2i"
   },
   "source": [
    "Since our model for Task A is capable of identifying interesting aspects in a sentence, we can move on to training a system for the next task of ABSA, ie. Sentiment Classification.\n",
    "In this task we want to associate a sentiment label (eg: Positive, Negative, Neutral) to each aspect found by our model from Task A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksZ6e4mGrn2i"
   },
   "source": [
    "#### B.1 Loading and checking your Data\n",
    "\n",
    "Once more, we will begin by first loading our data. The format of this file will look different than the previous file. This time we also need sentiment information for the aspects.\n",
    "\n",
    "For this task, we need our dataset to be stored in the Comma-seperated Values (CSV) format. Our sample datset is in **.xml format** which is why we use the following code cell to convert it to **.cvs format**. Your data might look different so make sure to adapt this code for your data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>aspect</th>\n",
       "      <th>category</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>456:0</td>\n",
       "      <td>أنصح بالنوم وليس تناول الطعام  موقع مثالي للإق...</td>\n",
       "      <td>موقع</td>\n",
       "      <td>LOCATION</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>456:1</td>\n",
       "      <td>كانت الغرفة ممتازة وكذلك الموظفون وبوفيه الإفط...</td>\n",
       "      <td>الغرفة</td>\n",
       "      <td>ROOMS</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>456:1</td>\n",
       "      <td>كانت الغرفة ممتازة وكذلك الموظفون وبوفيه الإفط...</td>\n",
       "      <td>الموظفون</td>\n",
       "      <td>SERVICE</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>456:1</td>\n",
       "      <td>كانت الغرفة ممتازة وكذلك الموظفون وبوفيه الإفط...</td>\n",
       "      <td>بوفيه الإفطار</td>\n",
       "      <td>FOOD_DRINKS</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>456:1</td>\n",
       "      <td>كانت الغرفة ممتازة وكذلك الموظفون وبوفيه الإفط...</td>\n",
       "      <td>وجبة العشاء</td>\n",
       "      <td>FOOD_DRINKS</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                           sentence  \\\n",
       "0       456:0  أنصح بالنوم وليس تناول الطعام  موقع مثالي للإق...   \n",
       "1       456:1  كانت الغرفة ممتازة وكذلك الموظفون وبوفيه الإفط...   \n",
       "2       456:1  كانت الغرفة ممتازة وكذلك الموظفون وبوفيه الإفط...   \n",
       "3       456:1  كانت الغرفة ممتازة وكذلك الموظفون وبوفيه الإفط...   \n",
       "4       456:1  كانت الغرفة ممتازة وكذلك الموظفون وبوفيه الإفط...   \n",
       "\n",
       "          aspect     category  polarity  \n",
       "0           موقع     LOCATION  positive  \n",
       "1         الغرفة        ROOMS  positive  \n",
       "2       الموظفون      SERVICE  positive  \n",
       "3  بوفيه الإفطار  FOOD_DRINKS  positive  \n",
       "4    وجبة العشاء  FOOD_DRINKS  negative  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "xml_path = \"AR_Hotels_Train_SB1.xml\"\n",
    "csv_path = \"ABSA_sentiment_output.csv\"\n",
    "\n",
    "excluded_categories = {\"ROOMS_AMENITIES\", \"FACILITIES\"}\n",
    "\n",
    "tree = ET.parse(xml_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "with open(csv_path, \"w\", encoding=\"utf-8\", newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=[\"sentence_id\", \"sentence\", \"aspect\", \"category\", \"polarity\"])\n",
    "    writer.writeheader()\n",
    "\n",
    "    for review in root.findall(\"Review\"):\n",
    "        for sentence in review.findall(\".//sentence\"):\n",
    "            text_element = sentence.find(\"text\")\n",
    "            if text_element is None or text_element.text is None:\n",
    "                continue\n",
    "\n",
    "            text = text_element.text.strip()\n",
    "            sentence_id = sentence.attrib.get(\"id\", \"\")\n",
    "\n",
    "            opinions = sentence.find(\"Opinions\")\n",
    "            if opinions is None:\n",
    "                continue\n",
    "\n",
    "            for opinion in opinions.findall(\"Opinion\"):\n",
    "                full_category = opinion.attrib.get(\"category\")\n",
    "                base_category = full_category.split(\"#\")[0]\n",
    "\n",
    "                if base_category in excluded_categories:\n",
    "                    continue  # Skip opinion\n",
    "\n",
    "                polarity = opinion.attrib.get(\"polarity\")\n",
    "                aspect = opinion.attrib.get(\"target\", \"\")\n",
    "\n",
    "                writer.writerow({\n",
    "                    \"sentence_id\": sentence_id,\n",
    "                    \"sentence\": text,\n",
    "                    \"aspect\": aspect,\n",
    "                    \"category\": base_category,\n",
    "                    \"polarity\": polarity\n",
    "                })\n",
    "\n",
    "df = pd.read_csv('ABSA_sentiment_output.csv')\n",
    "\n",
    "df.dropna(inplace=True) # Remove rows with missing values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gr8QkQLcrn2j"
   },
   "source": [
    "As you can see, the data format looks quite different this time. We have the full text in the **sentence** column. The aspect is stored in the **aspect** column. While the sentiment label we will use is in the **polarity** column. \n",
    "\n",
    "Lastly, now we will convert the data to a simpler format, ie. lists for easier processing in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_bgXwy8-rn2j"
   },
   "outputs": [],
   "source": [
    "sentence_list = list(df[\"sentence\"])\n",
    "aspect_list = list(df[\"aspect\"])\n",
    "tag_list = list(df[\"polarity\"])\n",
    "\n",
    "raw_data = [[sent, asp, tag] for sent, asp, tag in zip(sentence_list, aspect_list, tag_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZNms_d8rn2k"
   },
   "source": [
    "#### B.2 Load model & create tagset\n",
    "\n",
    "First let's define a few variables and load the model we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wYBT2xtzrn2k"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = 'Walid-Ahmed/arabic-sentiment-model' #This is the pre-trained model we are going to use. You can change this to any other model from the transformers library. To look for available models, you can visit https://huggingface.co/models\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # This will automatically use the GPU if it is available, otherwise it will use the CPU.\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uN8n1ncfrn2k"
   },
   "source": [
    "We need to assign a number to each sentiment label so the model can interpret it. In Task A this was done using the **corpus.make_label_dictionary** functionality, but that only works when using flair. For this Task, we will be using **transformers**, so we will have to find another way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3hfmzPRTrn2k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'positive', 1: 'neutral', 2: 'negative'}\n"
     ]
    }
   ],
   "source": [
    "tags = list(set(df[\"polarity\"]))\n",
    "tag2idx = {tag:idx for idx, tag in enumerate(tags)}\n",
    "idx2tag = {idx:tag for idx, tag in enumerate(tags)}\n",
    "print(idx2tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82fF-_EJrn2l"
   },
   "source": [
    "#### B.3 Helper functions for manipulating data\n",
    "\n",
    "Now we need to change the format of the data a bit. This is necessary because transformers break down words into smaller units called sub-words. This might cause some confusion, since an aspect can be broken down into multiple parts and only one part gets the annotated sentiment. In that case we also need to adjust our data so we can assign the sentiment label to all parts and not only one. To know more about how tokenization in transformers works and the technical details around it please take a look at [this guide](https://docs.mistral.ai/guides/tokenization/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NXLEWR0nrn2l"
   },
   "outputs": [],
   "source": [
    "#This functions finds the index position of the aspect term in the sentence\n",
    "\n",
    "def get_pos(sent_list,aspect_list):\n",
    "    first_pos = sent_list.index(aspect_list[1]) #first position bc [0] is always the CLS token in transformers\n",
    "    final_pos = []\n",
    "    for i in range(0,len(aspect_list)-2):\n",
    "        final_pos.append(first_pos+i)\n",
    "    return final_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "S2HnhBItrn2l"
   },
   "outputs": [],
   "source": [
    "#This class will construct a Torch dataset from the tagged sentences. Each instance in the dataset will contain the words, their position in the sentence and tags for those words.\n",
    "\n",
    "from torch.utils import data\n",
    "class ABSADataset(data.Dataset):\n",
    "    def __init__(self, tagged_sents):\n",
    "        sents, aspects, tags = [], [], [] # list of lists\n",
    "        bugged = 0\n",
    "        for sent in tagged_sents:\n",
    "            try:\n",
    "                sent_tokens = tokenizer.encode(sent[0])\n",
    "                aspect_tokens = tokenizer.encode(sent[1])\n",
    "                pos_aspects = get_pos(sent_tokens, aspect_tokens)\n",
    "                tag = sent[2]\n",
    "                sents.append(sent_tokens)\n",
    "                aspects.append(pos_aspects)\n",
    "                tags.append(tag)\n",
    "            except:\n",
    "                bugged+=1\n",
    "        print(\"Ignoring {} Buggy Annotations\".format(bugged))\n",
    "        self.sents, self.aspects, self.tags = sents, aspects, tags\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        words, aspects, tags = self.sents[idx], self.aspects[idx], tag2idx[self.tags[idx]] # words, tags: string list\n",
    "        return words, aspects, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpBJ4cOxrn2l"
   },
   "source": [
    "#### B.4 Creating our Model for extracting embeddings\n",
    "\n",
    "Let's wrap our loaded model in a class and then get embeddings for each aspect from the transformer. We will then use these embeddings to classify the sentiment of the aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TTl21lvXrn2l"
   },
   "outputs": [],
   "source": [
    "#This class defines a network where we pass full sentences to a transformer for the entire context but only store the embeddings for the aspect terms.\n",
    "#This is done by using the position index of the aspect term in the sentence we stored using our previous functions.\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "\n",
    "    def forward(self, sent, aspects, y):\n",
    "        '''\n",
    "        x: (N, T). int64\n",
    "        y: (N, T). int64\n",
    "        '''\n",
    "        sent = torch.LongTensor(sent).to(self.device)\n",
    "        aspects = torch.LongTensor(aspects).to(self.device)\n",
    "        y = torch.LongTensor(y).to(self.device)\n",
    "        input_ids = sent.unsqueeze(0)  # Batch size 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids)\n",
    "            last_hidden_states = outputs.last_hidden_state[0]  # Get last hidden state (embeddings)\n",
    "            start = 0\n",
    "            end = len(last_hidden_states)-1\n",
    "            context_window = 5 # define context window we're interested in (5 before and 5 after)\n",
    "\n",
    "            if aspects[0]-context_window>0:\n",
    "                start = aspects[0]-context_window\n",
    "            if aspects[-1]+context_window<len(last_hidden_states)-1:\n",
    "                end = aspects[-1]+context_window\n",
    "\n",
    "            all_aspects = []\n",
    "            for i in range(start,end):\n",
    "                all_aspects.append(i)\n",
    "\n",
    "            #For each index in all_aspects, it assigns the corresponding BERT embedding from the last_hidden_states tensor to the corresponding row in the bert_embeds tensor.\n",
    "            #Each row of bert_embeds now holds the BERT embedding for the corresponding aspect.\n",
    "\n",
    "            bert_embeds = torch.zeros(len(all_aspects),768).to(self.device)\n",
    "            for i, aspect in enumerate(all_aspects):\n",
    "                bert_embeds[i] = last_hidden_states[aspect]\n",
    "\n",
    "            #  calculates the mean of the embeddings along axis 0 (the rows).\n",
    "            #  This is done to obtain a single aggregated BERT embedding that represents the information from the context window around the aspects.\n",
    "\n",
    "            embedding = torch.mean(bert_embeds, axis=0).to(self.device)\n",
    "\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "95MfcniErn2m"
   },
   "outputs": [],
   "source": [
    "#This function will run our network from the previous cell on our entire dataset, therefore extracting and storing embeddings for each aspect term.\n",
    "\n",
    "def extract(model, iterator):\n",
    "    model.eval()\n",
    "\n",
    "    Words, Aspects, Y, Y_hat = [], [], [], [],\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            words, aspects, y = batch\n",
    "\n",
    "            _, _, y_hat, _ = model(words, aspects, y)  # y_hat: (N, T) = predicted labels\n",
    "            print(y_hat)\n",
    "\n",
    "            Words.extend(words)\n",
    "            Aspects.extend(aspects)\n",
    "            Y.extend(y.numpy().tolist())\n",
    "            Y_hat.extend([y_hat.cpu().numpy().tolist()])\n",
    "\n",
    "    ## calc metric\n",
    "    print(classification_report(Y, Y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umuo6_aErn2m"
   },
   "source": [
    "#### B.4 Initialising the Model & exctracting the embeddings\n",
    "\n",
    "Now we can begin to use all the massive functions we have defined in the previous sections and initialize first, our dataset, and then our model to be used for extracting the embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9aovPLGCrn2n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring 1085 Buggy Annotations\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "dataset = ABSADataset(raw_data)\n",
    "data_iterator = data.DataLoader(dataset=dataset,\n",
    "                             batch_size=1,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HE-Z9oBrn2n"
   },
   "source": [
    "Perfect! Now let's initalize our network for extracting the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BVed6mU6rn2n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(64000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rF_ITDlCrn2n"
   },
   "source": [
    "Great, now let's run this model on our entire data to extract embeddings for all the aspects. Again, remember that this can take quite a while, so take a break!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "joAcollern2n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6569it [00:47, 137.91it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "import tqdm\n",
    "for i, batch in tqdm.tqdm(enumerate(data_iterator)):\n",
    "        words, aspects, y = batch\n",
    "        embedding = model(words, aspects, y)\n",
    "        embedding = embedding.cpu().numpy()\n",
    "        y = int(y.cpu().numpy()[0])\n",
    "        embeddings.append([embedding, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHi2eU7grn2n"
   },
   "source": [
    "#### B.5 Setting up a Machine Learning Classifier\n",
    "\n",
    "Now that our embeddings are extracted. We can train a simple ML classifier to detect sentiment for an embedding. Let's first construct our data in the X (embeddings) and Y (labels) format of sklearn and then split it into a train and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "wrT8fOSGrn2o"
   },
   "outputs": [],
   "source": [
    "X = [x[0] for x in embeddings]\n",
    "Y = [x[1] for x in embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jF27v9S4rn2o"
   },
   "source": [
    "Let's see what a X and Y look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Sm-ECBg9rn2o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________ Sample Embedding ___________ \n",
      "[-5.93174212e-02 -1.81604221e-01 -3.63338083e-01 -6.40588328e-02\n",
      "  6.19046450e-01  4.83593971e-01 -3.74864876e-01  1.50123239e-01\n",
      "  7.52107203e-02  3.16303931e-02  4.83857632e-01  1.65168017e-01\n",
      "  3.32096145e-02 -4.12915885e-01  3.71975839e-01  2.77841181e-01\n",
      "  1.69453591e-01  5.51478490e-02  5.29130697e-01 -2.44303107e-01\n",
      " -2.87724454e-02  1.28027752e-01  8.64632964e-01 -6.92802966e-02\n",
      "  8.31239671e-02  2.06367955e-01 -1.81361586e-01 -3.00804824e-01\n",
      "  3.64042848e-01 -1.85096994e-01 -5.94020225e-02 -7.95968026e-02\n",
      " -2.49010324e-01 -1.32809937e-01  1.15697742e-01 -2.27052659e-01\n",
      " -5.83343878e-02 -1.39217302e-01 -8.89187306e-02 -6.06764317e-01\n",
      "  3.16121101e-01  8.44251364e-02  3.71199667e-01 -4.90562432e-02\n",
      "  6.68017745e-01  3.86537937e-03 -7.39151716e-01  4.71109927e-01\n",
      " -2.36981332e-01  2.26223841e-01 -1.07240953e-01 -2.08087310e-01\n",
      "  2.56718956e-02 -3.97177637e-02  4.57229204e-02  4.79988128e-01\n",
      "  2.88102001e-01  4.37300712e-01 -4.30738509e-01  1.45823762e-01\n",
      "  2.51328170e-01 -3.31379384e-01 -1.57611936e-01  4.16187823e-01\n",
      " -3.97246450e-01  2.70626754e-01  2.29252707e-02  1.39465481e-01\n",
      " -3.54785085e-01 -7.84008741e-01  1.19738668e-01  2.96376109e-01\n",
      " -1.43635139e-01  4.59276885e-02 -2.82905161e-01 -2.53933579e-01\n",
      " -4.44939993e-02 -1.05487183e-01  2.38985211e-01  6.86402202e-01\n",
      " -1.02368677e+00 -1.58284977e-01  5.22809327e-01  1.26764074e-01\n",
      " -1.98539689e-01 -4.84618098e-01 -4.04206216e-02 -5.65563031e-02\n",
      "  5.38260400e-01 -2.70347834e-01 -6.24673069e-02  4.01995808e-01\n",
      " -1.04623206e-01 -1.89790979e-01  2.22428486e-01 -4.52937841e-01\n",
      " -4.65301156e-01 -3.25854599e-01 -2.05105603e-01  1.65604621e-01\n",
      " -3.80479664e-01  5.37393093e-01 -6.38057172e-01  4.16217536e-01\n",
      "  3.97896975e-01  6.12031639e-01 -7.00680390e-02  1.02607720e-01\n",
      "  1.01154171e-01  2.60976881e-01 -2.38698632e-01  1.70643970e-01\n",
      "  5.00346065e-01 -8.23708892e-01 -3.01591992e-01  6.80126846e-01\n",
      "  4.58692670e-01 -5.93643039e-02  1.70230433e-01  3.89175378e-02\n",
      "  2.71089792e-01  1.74156055e-01 -2.96266466e-01 -3.12463284e-01\n",
      "  3.54844853e-02 -1.20090321e-01 -4.91936244e-02  8.55123550e-02\n",
      "  2.56820321e-01 -7.73799885e-03 -9.99952182e-02  1.25136197e-01\n",
      " -5.23513079e-01 -2.50314891e-01  1.43229172e-01  1.41463429e-01\n",
      " -2.29477838e-01  3.84297743e-02 -4.72390428e-02  7.46159852e-01\n",
      "  4.66320693e-01 -1.36416271e-01  4.25829351e-01 -4.93097663e-01\n",
      " -4.42608207e-01  2.11130187e-01 -2.20449835e-01 -3.00995022e-01\n",
      "  1.95082705e-02  6.72816411e-02 -3.50071758e-01  1.10882267e-01\n",
      "  1.00375209e-02  2.03816853e-02 -8.81817862e-02  1.05153807e-01\n",
      " -1.34940177e-01 -3.82638127e-01 -2.46381551e-01 -9.84681845e-01\n",
      " -2.03814447e-01 -4.57715802e-02 -7.32066989e-01  2.49390692e-01\n",
      " -9.72671583e-02  1.55175298e-01 -6.91675693e-02  8.46766867e-03\n",
      "  4.64660913e-01  2.08235681e-02  3.73166651e-01 -5.94703071e-02\n",
      "  8.91218066e-01 -2.36165494e-01  2.93566197e-01  3.52764279e-01\n",
      " -3.06976467e-01 -1.70455039e-01 -3.59851271e-01 -8.11977759e-02\n",
      "  1.68116003e-01  3.35975260e-01 -1.15299642e-01 -5.49823463e-01\n",
      " -9.67476442e-02  1.29416898e-01  2.37217903e-01  3.02672628e-02\n",
      " -2.95693070e-01  4.87439305e-01  3.80377114e-01  1.13979471e-03\n",
      " -4.90125895e-01  6.60590768e-01 -1.78282663e-01  3.13846827e-01\n",
      " -6.77444100e-01  1.75379768e-01  9.53192636e-02  2.17391938e-01\n",
      " -3.25116158e-01  6.43658191e-02 -2.56935600e-02 -1.67904392e-01\n",
      " -4.16171223e-01 -6.37150109e-01 -2.84938812e-01 -4.50892538e-01\n",
      " -1.17387995e-01 -6.63357258e-01  3.01937759e-01 -7.67513037e-01\n",
      "  1.18472822e-01 -2.03782376e-02  2.03684255e-01  5.97841501e-01\n",
      " -1.34602606e+00  1.92552462e-01  2.08398730e-01 -4.70611215e-01\n",
      " -1.86692253e-01  4.46871221e-01 -3.86533231e-01 -1.53009174e-02\n",
      " -9.01638791e-02 -3.00746292e-01  8.71990994e-02  5.37717104e-01\n",
      " -2.60475159e-01  8.71907055e-01 -1.34392863e-03  2.29246318e-01\n",
      "  4.31371152e-01  3.04453939e-01  3.80691677e-01 -3.07283461e-01\n",
      "  1.07823491e+00 -4.05194819e-01 -3.70864213e-01  1.05902299e-01\n",
      "  2.01256573e-01 -7.69952834e-01  1.84846342e-01 -3.26776087e-01\n",
      "  1.31330699e-01  6.68215692e-01 -1.89787522e-01 -3.72167856e-01\n",
      " -1.18996307e-01 -1.73721611e-01  2.18205377e-01 -2.67565906e-01\n",
      "  3.51775706e-01  1.54883966e-01 -8.76508281e-02 -4.21458870e-01\n",
      " -2.29247898e-01 -1.84362903e-01 -1.98539034e-01 -3.06130052e-01\n",
      " -9.88281667e-02  2.76769958e-02  3.20739865e-01 -3.75623256e-01\n",
      "  4.44346786e-01 -2.67074078e-01  3.15652251e-01 -2.41765171e-01\n",
      "  2.11818635e-01  1.01533130e-01 -5.84501445e-01  2.32844353e-01\n",
      "  8.25422257e-02  2.62868017e-01  7.19989657e-01  5.90651453e-01\n",
      " -4.22510743e-01  1.41901702e-01 -1.22175673e-02 -3.74238461e-01\n",
      " -1.81624070e-01 -1.58443898e-01  8.27674568e-01  1.56974268e+00\n",
      "  5.98333955e-01 -1.42534167e-01  9.54815522e-02 -3.31316233e-01\n",
      "  2.90015072e-01  5.76975524e-01  4.45149779e-01  5.62540233e-01\n",
      " -4.85595971e-01 -1.75661892e-01 -1.88925251e-01  7.40475655e-02\n",
      "  5.71838140e-01 -1.33948281e-01  3.14694792e-01  1.28404414e-02\n",
      " -5.22835791e-01 -1.28458723e-01 -1.09653151e+00  2.84998640e-02\n",
      " -1.81131214e-01  7.90081918e-02 -6.30873859e-01 -2.88381904e-01\n",
      " -2.18275145e-01 -4.50710058e-01  1.08044542e-01  2.99801648e-01\n",
      " -4.27969635e-01  2.16259420e-01  3.43895704e-02 -1.00457883e+00\n",
      " -4.57772985e-02 -3.47483516e-01 -6.31463051e-01 -6.90146610e-02\n",
      " -4.89337593e-01  1.20030808e+00 -1.10172093e-01  3.74094956e-03\n",
      " -4.05524850e-01 -6.96979612e-02  8.92661393e-01  5.28158061e-02\n",
      "  3.53817046e-01 -3.05776834e-01 -2.19751626e-01 -1.11516073e-01\n",
      "  5.57587072e-02  1.69186160e-01  4.42868143e-01  3.10143590e-01\n",
      " -3.88432890e-02 -1.51704341e-01 -4.08854336e-02  4.02943306e-02\n",
      " -2.65096903e-01  3.21822792e-01 -6.93116188e-02  4.13009003e-02\n",
      " -1.00783110e-02  4.54329252e-01 -8.84995535e-02  5.18445112e-02\n",
      " -6.48948610e-01  8.05088103e-01  9.14036706e-02 -2.50968034e-03\n",
      " -3.42495114e-01 -3.14870685e-01 -1.38492454e-02 -3.81013572e-01\n",
      "  1.85359329e-01 -1.12591825e-01 -2.20277593e-01  1.65407464e-01\n",
      "  3.76872480e-01  1.00191034e-01 -2.44534448e-01  3.16183090e-01\n",
      " -4.78639841e-01 -1.48196220e-01  1.06833681e-01  3.66911083e-01\n",
      "  2.65015811e-01  3.50560844e-01 -2.10280150e-01 -4.14601624e-01\n",
      "  8.49461183e-02  1.23514557e+00  1.81571886e-01 -1.26332149e-01\n",
      "  1.28868088e-01 -1.32211357e-01 -7.33866751e-01 -1.67780712e-01\n",
      " -2.24665314e-01 -7.32139170e-01 -3.97454619e-01 -4.51671593e-02\n",
      "  3.46803010e-01  3.63633893e-02  1.39383972e-01 -1.99718297e-01\n",
      "  4.08292681e-01  8.34979892e-01  1.21464241e+00 -1.60680532e-01\n",
      " -3.63898247e-01 -6.80884346e-03  9.15376022e-02 -3.53525996e-01\n",
      "  2.48893097e-01 -1.75488800e-01  9.95284796e-01  2.81845182e-01\n",
      "  7.62592614e-01 -1.37036189e-01 -1.56063512e-01 -2.31203020e-01\n",
      "  4.90068197e-01 -6.97574437e-01  7.43335187e-01  1.06523824e+00\n",
      "  5.69069684e-02 -1.31562233e-01 -3.01037937e-01 -2.21477836e-01\n",
      " -5.66188276e-01 -2.01503173e-01  3.73154432e-01 -1.61907777e-01\n",
      "  6.62971199e-01  2.06734374e-01 -4.59671170e-01 -6.08247280e-01\n",
      "  1.04464486e-01  1.15938717e-02 -3.51692110e-01  4.33924496e-01\n",
      " -8.43397796e-01  1.05461873e-01  9.37836096e-02  1.55938193e-01\n",
      "  6.06778085e-01  3.76128495e-01 -4.59626466e-01 -4.71551001e-01\n",
      "  9.36078370e-01  1.19541086e-01  6.20467179e-02  1.99681908e-01\n",
      " -1.53425083e-01  6.10668361e-01  3.51181805e-01  1.15783310e+00\n",
      "  5.87735064e-02  4.06463921e-01 -2.34003395e-01 -4.38724607e-01\n",
      "  9.16513875e-02 -3.31287771e-01  3.32945406e-01  7.45575363e-03\n",
      "  2.51497656e-01  3.69935453e-01 -1.91148683e-01 -2.47608066e-01\n",
      "  9.49379504e-02  5.62471569e-01  1.48587793e-01  9.67864320e-02\n",
      "  1.57871589e-01 -1.59909874e-01 -2.07940310e-01 -1.33673579e-01\n",
      "  5.04763603e-01  3.97114694e-01  1.90227196e-01  7.28458073e-03\n",
      " -9.78265330e-02 -2.12460965e-01 -9.64521095e-02 -4.73234713e-01\n",
      " -6.26375914e-01  1.01543806e-01 -1.72961935e-01 -4.69667017e-01\n",
      " -3.42099279e-01  1.49409503e-01  2.53586054e-01 -2.26873048e-02\n",
      " -2.24732071e-01 -8.37060690e-01 -1.45613641e-01 -3.29226315e-01\n",
      " -3.85648906e-01  1.85915321e-01  1.36101574e-01  1.14267871e-01\n",
      "  1.71542361e-01 -2.49807000e-01  2.69299626e-01  2.33890954e-02\n",
      " -3.35600972e-01  3.13436508e-01  2.84949005e-01 -8.22771251e-01\n",
      "  1.40183970e-01 -6.80122912e-01  1.01119883e-01  3.39402035e-02\n",
      "  1.49022445e-01 -9.91880447e-02 -6.36973798e-01 -4.00116026e-01\n",
      " -2.34141052e-01  1.92123607e-01  2.56258041e-01 -1.27821267e-01\n",
      " -8.41754019e-01  7.28983104e-01 -2.51907200e-01  2.21497729e-01\n",
      "  1.62864834e-01 -2.01419026e-01  4.53506745e-02  4.26624417e-01\n",
      " -6.13591850e-01 -8.12619746e-01  7.90710092e-01 -1.18448339e-01\n",
      "  5.20305455e-01 -6.01046113e-03  3.86117756e-01  3.53542209e-01\n",
      "  1.41329527e-01 -1.60282448e-01  4.20687377e-01  2.81816542e-01\n",
      "  1.86624259e-01 -2.53500998e-01  2.83820033e-01  5.15442967e-01\n",
      " -2.48646230e-01  4.74039793e-01  8.68288949e-02 -3.79027814e-01\n",
      "  1.51652068e-01 -1.76601689e-02  8.35911930e-02  2.89757848e-01\n",
      " -1.66834965e-01 -7.56227851e-01 -4.55915403e+00  1.83811679e-01\n",
      " -4.89243031e-01 -4.47528958e-01 -1.70892209e-01  3.97836119e-01\n",
      "  3.32560658e-01  7.10888728e-02 -3.57739511e-03  2.44772464e-01\n",
      "  2.17546463e-01  5.38839446e-03 -5.50274730e-01 -2.99954005e-02\n",
      "  1.84061140e-01  1.70941740e-01 -1.66291043e-01 -6.27668500e-01\n",
      "  7.24965334e-01  8.56478333e-01 -1.15288883e-01  5.25455236e-01\n",
      " -5.54808438e-01 -6.90973774e-02 -3.36639225e-01  1.80212334e-01\n",
      "  2.63010375e-02 -4.12492603e-01  2.48666450e-01  2.03145146e-02\n",
      "  2.70205975e-01 -4.39366519e-01  6.85959160e-02  4.16830927e-02\n",
      " -5.62429428e-01  5.98611543e-03  2.78208852e-01  3.93447995e-01\n",
      "  7.92270526e-02  2.89950520e-01  3.23614776e-01  6.52137995e-01\n",
      " -1.67191878e-01  4.82298851e-01 -9.62570757e-02 -8.72853994e-01\n",
      " -3.54725212e-01 -3.06720227e-01 -8.79525065e-01 -1.07509745e-02\n",
      " -2.65250236e-01 -5.05910575e-01 -3.48025620e-01 -2.36357361e-01\n",
      " -3.09500515e-01 -4.14031237e-01 -4.77536440e-01 -8.48577544e-02\n",
      " -3.66094679e-01 -3.94116551e-01  1.87757745e-01  3.42391133e-01\n",
      " -5.74955583e-01 -1.14380382e-02  1.21792816e-01  9.04182345e-02\n",
      "  2.46840954e-01 -1.65300161e-01  5.73263645e-01  1.55131042e-01\n",
      "  5.06576180e-01 -3.41842800e-01 -3.85628790e-01 -2.33141065e-01\n",
      "  6.26155257e-01  5.09171486e-01  2.50420302e-01 -1.49548218e-01\n",
      " -9.82726291e-02 -6.82466384e-03  6.46121860e-01 -3.70054506e-02\n",
      " -8.32521498e-01  1.67341530e-01 -9.70215276e-02 -1.13424934e-01\n",
      "  1.12552688e-01  2.29237378e-01 -2.22130701e-01 -2.28937939e-01\n",
      " -3.22429657e-01  2.01926187e-01 -2.54196793e-01 -4.82052833e-01\n",
      " -1.48790315e-01 -4.54641223e-01  2.90227085e-02  7.01835304e-02\n",
      " -4.27547157e-01 -4.18011874e-01 -1.36786506e-01  1.03621341e-01\n",
      " -2.81880945e-01 -2.03847140e-01  3.75903875e-01 -3.10536981e-01\n",
      "  5.01696944e-01 -8.12415719e-01  1.53948933e-01 -2.25614816e-01\n",
      " -8.18862617e-02  4.32467937e-01 -3.77098531e-01 -2.90069073e-01\n",
      " -2.88942158e-01 -1.02121599e-01  4.16763276e-02 -2.83833683e-01\n",
      "  2.99314916e-01 -1.47218332e-01  9.02124047e-01 -5.57497323e-01\n",
      "  6.88993573e-01 -1.76545277e-01 -6.67940229e-02  2.45393440e-01\n",
      " -1.10140047e-03  2.45936826e-01 -3.75725739e-02  3.82333100e-01\n",
      " -5.07676721e-01  4.31502700e-01  1.51147649e-01  2.19276205e-01\n",
      "  6.73647039e-03 -7.24746957e-02 -2.74128407e-01 -6.30722702e-01\n",
      "  2.21020386e-01 -2.38866881e-01 -5.47802225e-02 -1.09151574e-02\n",
      " -8.33245069e-02 -1.72818433e-02 -2.40525827e-02  3.12972933e-01\n",
      " -1.98696107e-01 -5.63417077e-01  2.73344576e-01 -3.88257802e-01\n",
      " -1.23695098e-01  2.54234850e-01 -1.59831852e-01 -9.16878954e-02\n",
      " -4.60223556e-01  6.77371383e-01  7.52393365e-01  2.33830124e-01\n",
      "  5.96954942e-01 -1.12098075e-01  8.08812261e-01  3.85681272e-01\n",
      "  4.19960171e-01 -4.19785887e-01 -1.35954142e-01  6.99053705e-01\n",
      "  3.13882589e-01 -1.36972770e-01 -3.28798264e-01 -4.73609477e-01\n",
      "  1.84871897e-01 -3.04766506e-01  3.82116996e-02  4.61709857e-01\n",
      "  9.56695452e-02 -1.36804208e-01 -4.00979608e-01  2.38233358e-01\n",
      " -7.01204896e-01 -5.55226654e-02 -3.74639854e-02 -3.46254498e-01\n",
      " -2.79075027e-01 -9.34819505e-02 -3.50468516e-01  4.11136121e-01\n",
      " -5.60780391e-02 -4.92166519e-01 -1.38578281e-01 -7.03565538e-01\n",
      "  7.49295950e-01 -7.00480342e-01  5.15715122e-01 -7.35311091e-01\n",
      " -1.17154539e+00 -1.43415093e-01  2.84613192e-01 -3.00473541e-01\n",
      "  3.43177140e-01 -4.62527066e-01  1.24624766e-01 -8.20555445e-03\n",
      "  1.06863594e+00  6.18654847e-01  1.53071344e-01 -3.89186531e-01\n",
      "  7.59209506e-03  4.57960516e-01 -4.31493610e-01  1.21621573e+00\n",
      "  3.60537797e-01  3.69456857e-01  3.01931113e-01 -2.83365339e-01\n",
      "  7.78884590e-02 -3.13733816e-01  2.74804700e-02 -3.45756710e-01\n",
      "  1.30781126e+00  5.93990207e-01  1.63536131e-01 -2.02044100e-01\n",
      " -6.14108369e-02  6.37671709e-01  4.03897196e-01  5.80799103e-01\n",
      "  9.80090648e-02 -1.15542494e-01  2.14908987e-01 -1.01610684e+00]\n",
      "___________ Sample Sentiment ___________ \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"___________ Sample Embedding ___________ \")\n",
    "print(X[100])\n",
    "print(\"___________ Sample Sentiment ___________ \")\n",
    "print(Y[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFuU5JL9rn2o"
   },
   "source": [
    "As you can see, X is a very long (768 dimensional) embedding of the aspect, while Y is the ID of the sentiment label (in this case 3)\n",
    "\n",
    "Let's split X and Y now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FGUVJ_K6rn2p"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=.2, shuffle=True, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7M8gK5kWrn2p"
   },
   "source": [
    "#### B.6 Train a ML Classifier on the Embeddings\n",
    "\n",
    "Finally let's train a simple Linear SVM on the Embeddings. You can of course try to experiment with the classifier you want to use. Depending on the size of the data and the amount of labels, there might be other better options. Some commonly used classifiers include Decision Trees, Multi-layer Perceptron, Random Forests, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "u_aCgNBern2p"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.025, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">0.025</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('kernel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">kernel&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;linear&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('degree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">degree&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;scale&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('coef0',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">coef0&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shrinking',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">shrinking&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('probability',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">probability&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cache_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cache_size&nbsp;</td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decision_function_shape',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decision_function_shape&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;ovr&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('break_ties',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">break_ties&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "SVC(C=0.025, kernel='linear')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel=\"linear\", C=0.025)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKka-yBIrn2q"
   },
   "source": [
    "Our  model is trained! Let's find it out how accurate it is on the Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "OCUn7680rn2q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       821\n",
      "           1       0.00      0.00      0.00        93\n",
      "           2       0.81      0.89      0.85       400\n",
      "\n",
      "    accuracy                           0.85      1314\n",
      "   macro avg       0.56      0.61      0.58      1314\n",
      "weighted avg       0.79      0.85      0.82      1314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "print(classification_report(y_test, predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ex12OgFDrn2q"
   },
   "source": [
    "As you can see, our model has an accuracy of 85% with more than 1000 labeled aspects labelled with sentiment used for training!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
